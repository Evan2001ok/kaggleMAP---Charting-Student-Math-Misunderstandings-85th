{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104383,"databundleVersionId":12957508,"sourceType":"competition"},{"sourceId":12719174,"sourceType":"datasetVersion","datasetId":8039184},{"sourceId":12729471,"sourceType":"datasetVersion","datasetId":8045877},{"sourceId":12925674,"sourceType":"datasetVersion","datasetId":8179015},{"sourceId":12983099,"sourceType":"datasetVersion","datasetId":8217527},{"sourceId":12983176,"sourceType":"datasetVersion","datasetId":8217578},{"sourceId":13093880,"sourceType":"datasetVersion","datasetId":8293734},{"sourceId":13116795,"sourceType":"datasetVersion","datasetId":8309112},{"sourceId":13165623,"sourceType":"datasetVersion","datasetId":8342331},{"sourceId":13202690,"sourceType":"datasetVersion","datasetId":8367326}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Model 1-2: Qwen 3 8b & Deepseek math 7b parallel\nRun deepseek on cuda:0 and qwen 3 on cuda:1","metadata":{}},{"cell_type":"code","source":"%%writefile qwen3_4b_inference.py\n\nimport os\nimport torch\nimport json\nimport pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding\n)\nfrom scipy.special import softmax\nfrom tqdm import tqdm\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n\nprint(\"Starting Qwen3-4B inference...\")\n\n# ============================================\n# Load Dataset\n# ============================================\ntrain = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\ntest = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n\n# ============================================\n# Feature Engineering - Correct Answer Lookup\n# ============================================\nidx = train.apply(lambda row: row.Category.split('_')[0], axis=1) == 'True'\ncorrect = train.loc[idx].copy()\ncorrect['c'] = correct.groupby(['QuestionId', 'MC_Answer']).MC_Answer.transform('count')\ncorrect = correct.sort_values('c', ascending=False).drop_duplicates(['QuestionId'])\ncorrect = correct[['QuestionId', 'MC_Answer']]\ncorrect['is_correct'] = 1\n\ntrain = train.merge(correct, on=['QuestionId','MC_Answer'], how='left')\ntrain.is_correct = train.is_correct.fillna(0)\n\ntest = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\ntest.is_correct = test.is_correct.fillna(0)\n\ndef format_input(row):\n    x = \"This answer is correct.\" if row['is_correct'] else \"This answer is incorrect.\"\n    return (\n        f\"Question: {row['QuestionText']}\\n\"\n        f\"Answer: {row['MC_Answer']}\\n\"\n        f\"{x}\\n\"\n        f\"Student Explanation: {row['StudentExplanation']}\"\n    )\n\ntest['text'] = test.apply(format_input, axis=1)\n\n# Create dataset\nds_test = Dataset.from_pandas(test[['row_id', 'text']])\n\n# ============================================\n# Load Model & Tokenizer\n# ============================================\nmodel_name = \"/kaggle/input/qwen3-4b-full-map-competition\"\n\n# Load label encoder mapping\nwith open(os.path.join(model_name, \"label_encoder.json\")) as f:\n    label_data = json.load(f)\ntarget_classes = label_data[\"classes\"]\nidx2label = {i: lbl for i, lbl in enumerate(target_classes)}\nlabel2idx = {lbl: i for i, lbl in enumerate(target_classes)}\n\nn_classes = len(target_classes)\nprint(f\"Number of classes: {n_classes}\")\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.pad_token_id = tokenizer.eos_token_id\n\nprint(\"Loading Qwen3-4B model...\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=n_classes,\n    device_map=\"auto\",\n    torch_dtype=torch.bfloat16\n)\nmodel.config.pad_token_id = tokenizer.pad_token_id\nmodel.eval()\n\n# Tokenize dataset\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n\nds_test = ds_test.map(tokenize, batched=True)\n\n# ============================================\n# Inference\n# ============================================\nprint(\"Running inference...\")\n\ntest_args = TrainingArguments(\n    output_dir=\"./qwen3_results\",\n    do_train=False,\n    do_predict=True,\n    per_device_eval_batch_size=16,\n    fp16=True,\n    bf16=False,\n    report_to='none'\n)\n\ntrainer = Trainer(\n    model=model,\n    args=test_args,\n    processing_class=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer)\n)\n\npredictions = trainer.predict(ds_test)\nprobs = softmax(predictions.predictions, axis=1)\n\n# ============================================\n# Generate Unified Output for Ensemble\n# ============================================\nprint(\"Generating unified interface output...\")\n\n# Get top-25 predictions\nTOP_K = 25\ntop_indices = np.argsort(-probs, axis=1)\n\n# Decode to class names\nflat_indices = top_indices.flatten()\ndecoded_labels = np.vectorize(idx2label.get)(flat_indices)\ntop_labels = decoded_labels.reshape(top_indices.shape)\n\n# Create standard submission (top-3)\ntop3_labels = top_labels[:, :3]\njoined_preds = [\" \".join(row) for row in top3_labels]\n\nsub = pd.DataFrame({\n    \"row_id\": test.row_id.values,\n    \"Category:Misconception\": joined_preds\n})\nsub.to_csv(\"submission_qwen3_4b.csv\", index=False)\n\n# Create probability file for ensemble\nprob_data = []\nfor i in range(len(test)):\n    prob_dict = {\n        'row_id': test.row_id.values[i],\n        'top_classes': \" \".join(top_labels[i, :TOP_K])\n    }\n    # Add probabilities for top-25 classes\n    for j in range(TOP_K):\n        prob_dict[f'prob_{j}'] = probs[i, top_indices[i, j]]\n    \n    prob_data.append(prob_dict)\n\nprob_df = pd.DataFrame(prob_data)\nprob_df.to_csv(\"submission_qwen3_4b_probabilities.csv\", index=False)\n\nprint(\"✅ Qwen3-4B inference completed!\")\nprint(f\"Generated files:\")\nprint(f\"  - submission_qwen3_4b.csv (standard submission)\")\nprint(f\"  - submission_qwen3_4b_probabilities.csv (for ensemble)\")\n\n# Clean up\ndel model, tokenizer\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T05:38:49.212627Z","iopub.execute_input":"2025-10-02T05:38:49.213382Z","iopub.status.idle":"2025-10-02T05:38:49.220803Z","shell.execute_reply.started":"2025-10-02T05:38:49.213356Z","shell.execute_reply":"2025-10-02T05:38:49.219987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile qwen3_deepseek_inference.py\n\n# we do parallel inference, for deepseek and qwen3\nimport os\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom datasets import Dataset\nimport threading\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding\nfrom scipy.special import softmax\nfrom tqdm import tqdm\nimport time\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n\ntrain = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\ntest  = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n\nmodel_paths = [\n    \"/kaggle/input/deekseepmath-7b-map-competition/MAP_EXP_09_FULL\",\n   \"/kaggle/input/qwen3-8b-map-competition/MAP_EXP_16_FULL\"]\n\ndef format_input(row):\n    x = \"This answer is correct.\"\n    if not row['is_correct']:\n        x = \"This is answer is incorrect.\"\n    return (\n        f\"Question: {row['QuestionText']}\\n\"\n        f\"Answer: {row['MC_Answer']}\\n\"\n        f\"{x}\\n\"\n        f\"Student Explanation: {row['StudentExplanation']}\")\n\n\nle = LabelEncoder()\ntrain.Misconception  = train.Misconception.fillna('NA')\ntrain['target']   = train.Category + ':' +train.Misconception\ntrain['label']    = le.fit_transform(train['target'])\n\nn_classes = len(le.classes_)\nprint(f\"Train shape: {train.shape} with {n_classes} target classes\")\nidx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\ncorrect = train.loc[idx].copy()\ncorrect['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\ncorrect = correct.sort_values('c',ascending=False)\ncorrect = correct.drop_duplicates(['QuestionId'])\ncorrect = correct[['QuestionId','MC_Answer']]\ncorrect['is_correct'] = 1\n\ntest = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\ntest.is_correct = test.is_correct.fillna(0)\ntest['text'] = test.apply(format_input,axis=1)\nds_test = Dataset.from_pandas(test)\n\n\ndef run_inference_on_gpu(model_path, gpu_id, test_data, output_name):\n    \"\"\"Run inference for one model on one GPU\"\"\"\n    \n    device = f\"cuda:{gpu_id}\"\n    print(f\"Loading {output_name} on {device}...\")\n    \n    # Load model\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_path, \n        device_map=device, \n        torch_dtype=torch.float16\n    )\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    model.config.pad_token_id = tokenizer.pad_token_id\n    model.eval()\n    \n    # Tokenize function\n    def tokenize(batch):\n        return tokenizer(batch[\"text\"], \n                        truncation=True,\n                        max_length=256)\n    \n    ds_test = Dataset.from_pandas(test_data[['text']])\n    ds_test = ds_test.map(tokenize, batched=True, remove_columns=['text'])\n    \n    # Data collator\n    data_collator = DataCollatorWithPadding(\n        tokenizer=tokenizer,\n        padding=True,\n        return_tensors=\"pt\"\n    )\n    \n    # DataLoader\n    dataloader = DataLoader(\n        ds_test,\n        batch_size=4,\n        shuffle=False,\n        collate_fn=data_collator,\n        pin_memory=True,\n        num_workers=0\n    )\n    \n    # Inference\n    all_logits = []\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=f\"{output_name}\"):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            all_logits.append(outputs.logits.float().cpu().numpy())\n    \n    predictions = np.concatenate(all_logits, axis=0)\n    \n    # Process results\n    probs = softmax(predictions, axis=1)\n    top_indices = np.argsort(-probs, axis=1)\n    \n    # Decode labels\n    flat_indices = top_indices.flatten()\n    decoded_labels = le.inverse_transform(flat_indices)\n    top_labels = decoded_labels.reshape(top_indices.shape)\n    \n    # Save top-3 submission\n    joined_preds = [\" \".join(row[:3]) for row in top_labels]\n    sub = pd.DataFrame({\n        \"row_id\": test_data.row_id.values,\n        \"Category:Misconception\": joined_preds\n    })\n    sub.to_csv(f\"submission_{output_name}.csv\", index=False)\n    \n    # Save probabilities for ensemble\n    prob_data = []\n    for i in range(len(predictions)):\n        prob_dict = {f\"prob_{j}\": probs[i, top_indices[i, j]] for j in range(25)}\n        prob_dict['row_id'] = test_data.row_id.values[i]\n        prob_dict['top_classes'] = \" \".join(top_labels[i, :25])\n        prob_data.append(prob_dict)\n    \n    prob_df = pd.DataFrame(prob_data)\n    prob_df.to_csv(f\"submission_{output_name}_probabilities.csv\", index=False)\n    \n    print(f\" {output_name} completed - saved submission and probabilities\")\n    \n    # Clean up GPU memory\n    del model, tokenizer\n    torch.cuda.empty_cache()\n\nprint(\" Starting multi-GPU inference...\")\nstart_time = time.time()\n\nthreads = []\ngpu_assignments = [\n    (model_paths[0], 0, \"deepseek\"),\n    (model_paths[1], 1, \"qwen3\"),\n]\n\n# Start threads\nfor model_path, gpu_id, name in gpu_assignments:\n    if gpu_id < torch.cuda.device_count():  \n        thread = threading.Thread(\n            target=run_inference_on_gpu,\n            args=(model_path, gpu_id, test, name)\n        )\n        threads.append(thread)\n        thread.start()\n        time.sleep(10)  # Stagger starts to avoid memory issues\n\n# Wait for completion\nfor thread in threads:\n    thread.join()\n\nend_time = time.time()\nprint(f\" completed in {end_time - start_time:.2f} seconds!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T05:27:36.082704Z","iopub.execute_input":"2025-10-02T05:27:36.083291Z","iopub.status.idle":"2025-10-02T05:27:36.104824Z","shell.execute_reply.started":"2025-10-02T05:27:36.083275Z","shell.execute_reply":"2025-10-02T05:27:36.104224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model 3: ettin encoder 1b 5fold","metadata":{}},{"cell_type":"code","source":"%%writefile ettin_inference.py\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport gc\nimport os\n\n# Disable wandb\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# For multi-GPU if needed (adjust based on your needs)\n# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n\n# ============================================\n# Configuration\n# ============================================\n\nMODEL_PATHS = [\n    \"/kaggle/input/ettin-encoder1b-5fold/content/drive/MyDrive/models/ver_1_5fold/fold_0/final_model\", \n    \"/kaggle/input/ettin-encoder1b-5fold/content/drive/MyDrive/models/ver_1_5fold/fold_1/final_model\",\n    \"/kaggle/input/ettin-encoder1b-5fold/content/drive/MyDrive/models/ver_1_5fold/fold_2/final_model\",\n    \"/kaggle/input/ettin-encoder1b-5fold/content/drive/MyDrive/models/ver_1_5fold/fold_3/final_model\",\n    \"/kaggle/input/ettin-encoder1b-5fold/content/drive/MyDrive/models/ver_1_5fold/fold_4/final_model\",\n]\n\n# ============================================\n# Setup\n# ============================================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ============================================\n# Data Preparation\n# ============================================\n\nprint(\"Loading data...\")\ntest = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\ntrain = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n\n# Prepare label encoder (same as other models)\ntrain['Misconception'] = train['Misconception'].fillna('NA')\ntrain['target'] = train['Category'] + \":\" + train['Misconception']\nle = LabelEncoder()\nle.fit(train['target'])\nnum_classes = len(le.classes_)\nprint(f\"Number of classes: {num_classes}\")\n\n# Add is_correct feature\nidx = train.apply(lambda row: row.Category.split('_')[0], axis=1) == 'True'\ncorrect = train.loc[idx].copy()\ncorrect['c'] = correct.groupby(['QuestionId', 'MC_Answer']).MC_Answer.transform('count')\ncorrect = correct.sort_values('c', ascending=False).drop_duplicates(['QuestionId'])\ncorrect = correct[['QuestionId', 'MC_Answer']]\ncorrect['is_correct'] = 1\n\ntest = test.merge(correct, on=['QuestionId', 'MC_Answer'], how='left')\ntest['is_correct'] = test['is_correct'].fillna(0)\n\n# Format input text\ndef format_input(row):\n    x = \"Yes\" if row['is_correct'] else \"No\"\n    return f\"Question: {row['QuestionText']}\\nAnswer: {row['MC_Answer']}\\nCorrect? {x}\\nStudent Explanation: {row['StudentExplanation']}\"\n\ntest['text'] = test.apply(format_input, axis=1)\n\n# ============================================\n# Batch Prediction Function\n# ============================================\n\ndef batch_predict(model, tokenizer, texts, batch_size=8, max_length=256):\n    all_probs = []\n    \n    for i in tqdm(range(0, len(texts), batch_size), desc=\"Inference\"):\n        batch_texts = texts[i:i+batch_size]\n        \n        inputs = tokenizer(\n            batch_texts,\n            padding=True,\n            truncation=True,\n            max_length=max_length,\n            return_tensors='pt'\n        )\n        \n        with torch.no_grad():\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            outputs = model(**inputs)\n            \n            batch_probs = torch.nn.functional.softmax(\n                outputs.logits.float(), dim=-1\n            ).cpu().numpy()\n            \n            all_probs.append(batch_probs)\n            \n            del outputs, inputs\n            if i % 100 == 0:\n                torch.cuda.empty_cache()\n    \n    return np.vstack(all_probs)\n\n# ============================================\n# Process Each Fold\n# ============================================\n\nprint(\"Starting 5-fold inference...\")\nall_fold_probs = []\n\nfor fold_idx, model_path in enumerate(MODEL_PATHS):\n    print(f\"\\nProcessing Fold {fold_idx + 1}/{len(MODEL_PATHS)}\")\n    \n    try:\n        # Load tokenizer\n        tokenizer = AutoTokenizer.from_pretrained(model_path)\n        if tokenizer.pad_token is None:\n            tokenizer.pad_token = tokenizer.eos_token\n        \n        # Load model\n        model = AutoModelForSequenceClassification.from_pretrained(\n            model_path,\n            num_labels=num_classes,\n            torch_dtype=torch.float16,\n            device_map=None,\n        ).to(device)\n        \n        model.eval()\n        \n        # Predict\n        fold_probs = batch_predict(\n            model, \n            tokenizer, \n            test['text'].tolist(),\n            batch_size=8,\n            max_length=256\n        )\n        \n        all_fold_probs.append(fold_probs)\n        \n        # Clean up\n        del model\n        del tokenizer\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        print(f\"✅ Fold {fold_idx + 1} completed\")\n        \n    except Exception as e:\n        print(f\"❌ Error in fold {fold_idx + 1}: {str(e)}\")\n        continue\n\n# ============================================\n# Ensemble and Generate Output\n# ============================================\n\nprint(\"\\nEnsembling predictions...\")\nensemble_probs = np.mean(all_fold_probs, axis=0)\n\n# Get top-25 predictions\ntop_indices = np.argsort(-ensemble_probs, axis=1)\n\n# Decode to class names\nflat_indices = top_indices.flatten()\ndecoded_labels = le.inverse_transform(flat_indices)\ntop_labels = decoded_labels.reshape(top_indices.shape)\n\n# Create standard submission (top 3)\njoined_preds = [\" \".join(row[:3]) for row in top_labels]\nsub = pd.DataFrame({\n    \"row_id\": test.row_id.values,\n    \"Category:Misconception\": joined_preds\n})\nsub.to_csv(\"submission_ettin.csv\", index=False)\n\n# Create probability file for ensemble\nprob_data = []\nfor i in range(len(test)):\n    prob_dict = {f\"prob_{j}\": ensemble_probs[i, top_indices[i, j]] for j in range(25)}\n    prob_dict['row_id'] = test.row_id.values[i]\n    prob_dict['top_classes'] = \" \".join(top_labels[i, :25])\n    prob_data.append(prob_dict)\n\nprob_df = pd.DataFrame(prob_data)\nprob_df.to_csv(\"submission_ettin_probabilities.csv\", index=False)\n\nprint(\"✅ Ettin inference completed!\")\nprint(f\"Generated: submission_ettin.csv and submission_ettin_probabilities.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T05:27:36.106063Z","iopub.execute_input":"2025-10-02T05:27:36.106272Z","iopub.status.idle":"2025-10-02T05:27:36.124543Z","shell.execute_reply.started":"2025-10-02T05:27:36.106257Z","shell.execute_reply":"2025-10-02T05:27:36.123735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model 4: Hunyuan_7b","metadata":{}},{"cell_type":"code","source":"%%writefile hunyuan_inference_safe.py\n\nimport os\nimport sys\n\n# 不升级transformers，直接使用当前版本\nprint(\"Using current transformers version...\")\n\n# 设置环境变量\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom argparse import Namespace\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.special import softmax\n\n# DataProcessor类（保持不变）\nclass DataProcessor:\n    def __init__(self, args):\n        self.args = args\n        self.le = None\n        self.isPreprocess = False\n        self.correct_lookup = None\n\n    def load_data(self):\n        self.train_df = pd.read_csv(self.args.train_path)\n        self.test_df = pd.read_csv(self.args.test_path)\n\n    def get_num_classes(self):\n        if not self.isPreprocess:\n            return \"please preprocess first\"\n        return self.train_df['label'].nunique()\n\n    def get_label_encoder(self):\n        if self.le is None:\n            raise ValueError(\"LabelEncoder not initialized.\")\n        return self.le\n\n    @staticmethod\n    def format_input(row):\n        correct_text = \"Yes\" if row['IsCorrect'] else \"No\"\n        return (\n            f\"Question: {row['QuestionText']}\\n\"\n            f\"Answer: {row['MC_Answer']}\\n\"\n            f\"Correct? {correct_text}\\n\"\n            f\"Student Explanation: {row['StudentExplanation']}\\n\"\n        )\n\n    def preprocess(self):\n        self.load_data()\n        \n        # 标准化标签编码\n        self.train_df['Misconception'] = self.train_df['Misconception'].fillna('NA')\n        self.train_df['target'] = self.train_df['Category'] + ':' + self.train_df['Misconception']\n\n        # 获取正确答案\n        correct_samples = self.train_df[self.train_df['Category'].str.startswith('True', na=False)].copy()\n        correct_samples['count'] = correct_samples.groupby(['QuestionId', 'MC_Answer'])['MC_Answer'].transform('count')\n        most_popular_correct = correct_samples.sort_values('count', ascending=False).drop_duplicates(['QuestionId'])\n        self.correct_lookup = most_popular_correct[['QuestionId', 'MC_Answer']].copy()\n        self.correct_lookup['IsCorrect_flag'] = True\n\n        self.train_df = self.train_df.merge(self.correct_lookup, on=['QuestionId', 'MC_Answer'], how='left')\n        self.train_df['IsCorrect'] = self.train_df['IsCorrect_flag'].notna()\n        self.train_df = self.train_df.drop(columns=['IsCorrect_flag'])\n\n        self.le = LabelEncoder()\n        self.train_df['label'] = self.le.fit_transform(self.train_df['target'])\n        self.train_df['text'] = self.train_df.apply(self.format_input, axis=1)\n\n        self.isPreprocess = True\n        return self.train_df\n\n    def inference_processor(self):\n        if not self.isPreprocess:\n            return \"Please preprocess first\"\n        self.test_df = self.test_df.merge(self.correct_lookup, on=['QuestionId', 'MC_Answer'], how='left')\n        self.test_df['IsCorrect'] = self.test_df['IsCorrect_flag'].notna()\n        self.test_df = self.test_df.drop(columns=['IsCorrect_flag'])\n        self.test_df['text'] = self.test_df.apply(self.format_input, axis=1)\n        return self.test_df\n\n# 配置参数\nargs = Namespace(\n    train_path='/kaggle/input/map-charting-student-math-misunderstandings/train.csv',\n    test_path='/kaggle/input/map-charting-student-math-misunderstandings/test.csv',\n    model_dir=\"/kaggle/input/hunyuan-7b-instruct-map\",\n    inference_model_dir=\"/kaggle/input/hunyuan-7b-instruct-map\",\n    model_name=\"/kaggle/input/hunyuan-7b-instruct-bf16\"\n)\n\nprint(\"Preprocessing data...\")\nDP = DataProcessor(args)\n_ = DP.preprocess()\nnum_classes = DP.get_num_classes()\nprint(f\"Number of classes: {num_classes}\")\n\ntry:\n    # 尝试导入transformers\n    from datasets import Dataset\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n    from peft import PeftModel\n    \n    print(\"Loading tokenizer and model...\")\n    tokenizer = AutoTokenizer.from_pretrained(args.inference_model_dir, trust_remote_code=True)\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    # 加载基座模型 + LoRA\n    print(\"Loading base model...\")\n    base_model = AutoModelForSequenceClassification.from_pretrained(\n        args.model_name,\n        num_labels=num_classes,\n        device_map=\"auto\",\n        torch_dtype=torch.float16,\n        trust_remote_code=True  # 添加这个参数\n    )\n    \n    print(\"Loading LoRA weights...\")\n    model = PeftModel.from_pretrained(base_model, args.inference_model_dir)\n    model.config.pad_token_id = tokenizer.pad_token_id\n    model.eval()\n\n    # Tokenize函数\n    MAX_LEN = 256\n    def tokenize_function(examples):\n        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n\n    # 准备测试数据\n    print(\"Preparing test data...\")\n    test_df = DP.inference_processor()\n    ds_test = Dataset.from_pandas(test_df[['text']])\n    ds_test = ds_test.map(tokenize_function, batched=True)\n\n    # 推理设置\n    inference_args = TrainingArguments(\n        do_train=False,\n        do_eval=True,\n        output_dir=\"./results_hunyuan\",\n        per_device_eval_batch_size=16,\n        fp16=True,\n        bf16=False,\n        report_to=\"none\",\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=inference_args,\n        processing_class=tokenizer,\n    )\n\n    # 执行推理\n    print(\"Running inference...\")\n    pred = trainer.predict(ds_test)\n    probs = torch.nn.functional.softmax(torch.tensor(pred.predictions), dim=1).numpy()\n\n    # ============================================\n    # 生成统一接口输出\n    # ============================================\n\n    print(\"Generating unified interface output...\")\n\n    # 获取top-25预测\n    TOP_K = 25\n    top_indices = np.argsort(-probs, axis=1)\n\n    # 解码为类别名\n    flat_indices = top_indices.flatten()\n    le = DP.get_label_encoder()\n    decoded_labels = le.inverse_transform(flat_indices)\n    top_labels = decoded_labels.reshape(top_indices.shape)\n\n    # 创建标准提交文件（top-3）\n    top3_labels = top_labels[:, :3]\n    joined_preds = [\" \".join(row) for row in top3_labels]\n\n    sub = pd.DataFrame({\n        \"row_id\": test_df.row_id.values,\n        \"Category:Misconception\": joined_preds\n    })\n    sub.to_csv(\"submission_hunyuan.csv\", index=False)\n\n    # 创建概率文件\n    prob_data = []\n    for i in range(len(test_df)):\n        prob_dict = {\n            'row_id': test_df.row_id.values[i],\n            'top_classes': \" \".join(top_labels[i, :TOP_K])\n        }\n        for j in range(TOP_K):\n            prob_dict[f'prob_{j}'] = probs[i, top_indices[i, j]]\n        \n        prob_data.append(prob_dict)\n\n    prob_df = pd.DataFrame(prob_data)\n    prob_df.to_csv(\"submission_hunyuan_probabilities.csv\", index=False)\n\n    print(\"✅ Hunyuan inference completed!\")\n    print(f\"Generated files:\")\n    print(f\"  - submission_hunyuan.csv\")\n    print(f\"  - submission_hunyuan_probabilities.csv\")\n\nexcept Exception as e:\n    print(f\"❌ Error occurred: {e}\")\n    print(\"\\nTrying alternative approach without Hunyuan model...\")\n    \n    # 如果Hunyuan失败，创建一个占位文件以便其他模型可以继续\n    print(\"Creating placeholder files for ensemble compatibility...\")\n    \n    # 使用简单的随机预测作为备份\n    test_df = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n    \n    # 创建空的概率文件（让集成可以继续，只是不包含Hunyuan）\n    print(\"⚠️ Hunyuan model failed, proceeding without it\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T05:27:36.12524Z","iopub.execute_input":"2025-10-02T05:27:36.125407Z","iopub.status.idle":"2025-10-02T05:27:36.145471Z","shell.execute_reply.started":"2025-10-02T05:27:36.125394Z","shell.execute_reply":"2025-10-02T05:27:36.144913Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Run inference","metadata":{"execution":{"iopub.status.busy":"2025-09-05T05:24:19.922686Z","iopub.execute_input":"2025-09-05T05:24:19.923503Z","iopub.status.idle":"2025-09-05T05:24:19.927662Z","shell.execute_reply.started":"2025-09-05T05:24:19.923473Z","shell.execute_reply":"2025-09-05T05:24:19.926846Z"}}},{"cell_type":"code","source":"import time \n!python /kaggle/working/qwen3_4b_inference.py \ntime.sleep(10)\n!python /kaggle/working/qwen3_deepseek_inference.py\ntime.sleep(10)\n!python /kaggle/working/ettin_inference.py\ntime.sleep(10)\n!pip install --upgrade --no-index --find-links=/kaggle/input/transformers-4-56-1-and-deps transformers -qq\n!python /kaggle/working/hunyuan_inference_safe.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T05:38:58.956749Z","iopub.execute_input":"2025-10-02T05:38:58.957021Z","iopub.status.idle":"2025-10-02T05:40:40.20721Z","shell.execute_reply.started":"2025-10-02T05:38:58.957002Z","shell.execute_reply":"2025-10-02T05:40:40.206285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ensemble ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import defaultdict\nfrom scipy.special import softmax\n\n\n\ndef extract_class_probabilities(row, model_suffix='', top_k=25):\n    \"\"\"Extract class names and probabilities from a row\"\"\"\n    # Get top classes\n    classes_col = f'top_classes{model_suffix}'\n    if classes_col in row:\n        classes = row[classes_col].split(' ')[:top_k]\n    else:\n        return {}\n    # Get probabilities\n    class_probs = {}\n    for i in range(min(top_k, len(classes))):\n        prob_col = f'prob_{i}{model_suffix}'\n        if prob_col in row:\n            class_probs[classes[i]] = row[prob_col]\n    return class_probs\n\n\ndef ensemble_with_disagreement_handling(prob_files, model_weights=None, top_k=3):\n    n_models = len(prob_files)\n    prob_dfs = []\n    final_predictions = []\n    \n    for file_path in prob_files:\n        df = pd.read_csv(file_path)\n        prob_dfs.append(df)\n    \n    # Merge on row_id\n    merged_df = prob_dfs[0]\n    for i, df in enumerate(prob_dfs[1:], 1):\n        merged_df = pd.merge(merged_df, df, on='row_id', suffixes=('', f'_model{i+1}'))\n      \n    for idx, row in merged_df.iterrows():\n        \n        # Extract probabilities from each model\n        all_class_probs = []\n        for i in range(n_models):\n            suffix = f'_model{i+1}' if i > 0 else ''\n            class_probs = extract_class_probabilities(row, suffix, top_k=25)\n            all_class_probs.append(class_probs)\n        \n        # Get all unique classes\n        all_classes = set()\n        for class_probs in all_class_probs:\n            all_classes.update(class_probs.keys())\n        \n        # Calculate agreement and disagreement\n        class_votes = defaultdict(int)\n        class_total_prob = defaultdict(float)\n        class_max_prob = defaultdict(float)\n        \n        for i, class_probs in enumerate(all_class_probs):\n            weight = model_weights[i]\n            \n            for class_name, prob in class_probs.items():\n                class_votes[class_name] += 1\n                class_total_prob[class_name] += prob * weight\n                class_max_prob[class_name] = max(class_max_prob[class_name], prob * weight)\n        \n        final_scores = {}\n        for class_name in all_classes:\n            \n            # Base score: weighted average probability\n            base_score = class_total_prob[class_name]\n            \n            # Agreement : classes predicted by more models get boost\n            agreement_bonus = class_votes[class_name] / n_models\n            \n            # Confidence bonus: classes with high max probability get boost\n            confidence_bonus = class_max_prob[class_name]\n            \n            # Combined score\n            final_scores[class_name] = (\n                base_score * 0.6 +           # 60% base probs\n                agreement_bonus * 0.3 +      # 30% agreement\n                confidence_bonus * 0.1       # 10% confidence\n            )\n        \n        # Sort and get top-k\n        sorted_classes = sorted(final_scores.items(), key=lambda x: -x[1])\n        top_classes = [class_name for class_name, _ in sorted_classes[:top_k]]\n        \n        final_predictions.append(' '.join(top_classes))\n    \n    return final_predictions\n\n# single models scores\n# deepseek math 7b - 0.944\n# qwen3 8b - 0.943\n# ettin encoder 1b - 0.944\n# hunyuan_inference lb - 0.945\nw0 = 1.0\nw1 = 1.0  \nw2 = 1.0  \nw3 = 1.0  \nw4 = 1.1  \n\nprob_files = [\n    '/kaggle/working/submission_qwen3_4b_probabilities.csv',\n    '/kaggle/working/submission_deepseek_probabilities.csv',\n    '/kaggle/working/submission_qwen3_probabilities.csv',\n    '/kaggle/working/submission_ettin_probabilities.csv',\n    '/kaggle/working/submission_hunyuan_probabilities.csv'\n\n]\n\n\npredictions = ensemble_with_disagreement_handling(\n        prob_files, \n        model_weights=[w0, w1, w2, w3, w4],  \n        top_k=3\n    )\n    \ntest_df = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n\nsubmission = pd.DataFrame({\n    'row_id': test_df.row_id.values,\n    'Category:Misconception': predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T05:40:43.013601Z","iopub.execute_input":"2025-10-02T05:40:43.014208Z","iopub.status.idle":"2025-10-02T05:40:43.149603Z","shell.execute_reply.started":"2025-10-02T05:40:43.014181Z","shell.execute_reply":"2025-10-02T05:40:43.149033Z"}},"outputs":[],"execution_count":null}]}